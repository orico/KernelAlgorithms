{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Time-Complexity Benchmarking for Kernel & Non-Kernel Algorithms",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orico/KernelAlgorithms/blob/master/Time_Complexity_Benchmarking_for_Kernel_%26_Non_Kernel_Algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MWwUTInv-oj",
        "colab_type": "code",
        "outputId": "5897e27a-e80b-4537-cfba-4a3ada6dae36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "from scipy.stats import norm, multivariate_normal, matrix_normal, gaussian_kde\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# from sklearn.utils import check_random_state\n",
        "from sklearn.datasets import load_digits, fetch_mldata, fetch_california_housing, load_breast_cancer\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.cluster import KMeans \n",
        "from sklearn.svm import LinearSVC, SVC \n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.neighbors.kde import KernelDensity\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "import gc \n",
        "\n",
        "!pip install memory_profiler\n",
        "%load_ext memory_profiler\n",
        "!pip install cython \n",
        "!pip install tslearn\n",
        "from tslearn.clustering import GlobalAlignmentKernelKMeans"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: memory_profiler in /usr/local/lib/python3.6/dist-packages (0.55.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from memory_profiler) (5.4.8)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.10)\n",
            "Requirement already satisfied: tslearn in /usr/local/lib/python3.6/dist-packages (0.1.29)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from tslearn) (0.21.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from tslearn) (0.29.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tslearn) (1.16.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from tslearn) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->tslearn) (0.13.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrFIsF1wvzCg",
        "colab_type": "text"
      },
      "source": [
        "We start by downloading our data and splitting it to train and test, according to known MNIST definitions 60K/10K split. later the train-set will be split to train and validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ojzg4Gjwpgh",
        "colab_type": "code",
        "outputId": "14ae7693-b80a-4c62-97de-352355b9e6d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "class Normalize(object):\n",
        "    \n",
        "    def normalize(self, X_train, X_test):\n",
        "        self.scaler = MinMaxScaler()\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_test  = self.scaler.transform(X_test)\n",
        "        return (X_train, X_test)\n",
        "    \n",
        "    def inverse(self, X_train, X_test):\n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_test  = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_test) \n",
        "       \n",
        "data = load_breast_cancer() #fetch_mldata('MNIST original')\n",
        "X = data.data.astype('float64')\n",
        "y = data.target\n",
        "\n",
        "print ('Data:', X.shape, y.shape)\n",
        "\n",
        "#split train/val/test \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "print(X_train.shape, np.unique(y_train))\n",
        "print(X_test.shape, np.unique(y_test))\n",
        "\n",
        "norm_ = Normalize()\n",
        "X_train, X_test = norm_.normalize(X_train, X_test)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data: (569, 30) (569,)\n",
            "(512, 30) [0 1]\n",
            "(57, 30) [0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2coy8C7xGqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calcAcc(clf):\n",
        "  classif_rate = np.mean(clf.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
        "  print(\"Accuracy rate for %f \" % (classif_rate))    \n",
        "  print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, clf.test_y_predicted))\n",
        "  \n",
        "class BaseModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self):\n",
        "        pass\n",
        "      \n",
        "    def predict_or_transform(self):\n",
        "        pass\n",
        "      \n",
        "      \n",
        "class SvmModel(BaseModel):\n",
        "  \n",
        "    def fit(self, X_train, y_train, c_weight):\n",
        "        self.model = SVC(C=1, kernel='linear', probability=True, class_weight=c_weight)\n",
        "        self.model.fit(X_train, y_train)\n",
        "        \n",
        "    def predict_or_transform(self, X_test):\n",
        "        self.test_y_predicted = self.model.predict(X_test) \n",
        "\n",
        "        \n",
        "class LinearSvmModell2(BaseModel):\n",
        "  \n",
        "    def fit(self, X_train, y_train, c_weight):\n",
        "        self.model = clf = LinearSVC(random_state=42, class_weight=c_weight)\n",
        "        self.model.fit(X_train, y_train)\n",
        "        \n",
        "    def predict_or_transform(self, X_test):\n",
        "        self.test_y_predicted = self.model.predict(X_test) \n",
        "        \n",
        "        \n",
        "class LinearSvmModell1(BaseModel):\n",
        "  \n",
        "    def fit(self, X_train, y_train, c_weight):\n",
        "        self.model = clf = LinearSVC(random_state=42, penalty = 'l1', class_weight=c_weight)\n",
        "        self.model.fit(X_train, y_train)\n",
        "        \n",
        "    def predict_or_transform(self, X_test):\n",
        "        self.test_y_predicted = self.model.predict(X_test) \n",
        "        \n",
        "        \n",
        "class PCAModel(BaseModel):\n",
        "  \n",
        "    def fit(self, X_train, y_train, c_weight):\n",
        "        self.model = PCA()\n",
        "        self.model.fit(X_train)     \n",
        "      \n",
        "    def predict_or_transform(self, X_test):\n",
        "        self.X_test_trans = self.model.transform(X_test)\n",
        "        \n",
        "        \n",
        "class KernelPCAModel(BaseModel):\n",
        "  \n",
        "    def fit(self, X_train, y_train, c_weight):\n",
        "        self.model = KernelPCA(kernel = 'linear')\n",
        "        self.model.fit(X_train)          \n",
        "\n",
        "    def predict_or_transform(self, X_test):\n",
        "        self.X_test_trans = self.model.transform(X_test)\n",
        "        \n",
        "        \n",
        "class KernelKmeansModel(BaseModel):\n",
        "  \n",
        "    def fit(self, X_train, y_train, c_weight):\n",
        "        self.model = GlobalAlignmentKernelKMeans(n_clusters=2, verbose = 0)\n",
        "        self.model.fit(X_train)         \n",
        "\n",
        "    def predict_or_transform(self, X_test):\n",
        "        self.X_test_trans = self.model.predict(X_test)\n",
        "        \n",
        "        \n",
        "class KmeansModel(BaseModel):\n",
        "  \n",
        "    def fit(self, X_train, y_train, c_weight):\n",
        "        self.model = KMeans(n_clusters=2)\n",
        "        self.model.fit(X_train)           \n",
        "\n",
        "    def predict_or_transform(self, X_test):\n",
        "        self.X_test_trans = self.model.predict(X_test)        \n",
        "      \n",
        "        \n",
        "class KDEModel(BaseModel):\n",
        "  \n",
        "    def fit(self, X_train, y_train, c_weight):\n",
        "        self.model = KernelDensity()\n",
        "        self.model.fit(X_train)           \n",
        "\n",
        "    def predict_or_transform(self, X_test):\n",
        "        self.X_test_trans = self.model.score_samples(X_test)        \n",
        "\n",
        "\n",
        "class GaussianMixtureModel(BaseModel):\n",
        "  \n",
        "    def fit(self, X_train, y_train, c_weight):\n",
        "        self.model = GaussianMixture(n_components=2)\n",
        "        self.model.fit(X_train)           \n",
        "    \n",
        "    def predict_or_transform(self, X_test):\n",
        "        self.X_test_trans = self.model.transform(X_test)         \n",
        "        \n",
        "        \n",
        "class PDFModel(BaseModel):\n",
        "  \n",
        "    def fit(self, X_train, y_train, c_weight):  \n",
        "        self.model = norm.pdf(X_train)\n",
        "    \n",
        "    def predict_or_transform(self, X_test):\n",
        "        pass\n",
        "#         self.X_test_trans = self.model.transform(X_test)                 \n",
        "\n",
        "class GaussianKdeModel(BaseModel):\n",
        "  \n",
        "    def fit(self, X_train, y_train, c_weight):  \n",
        "        self.model = gaussian_kde(X_train.T)\n",
        "    \n",
        "    def predict_or_transform(self, X_test): \n",
        "        self.X_test_trans = self.model.evaluate(X_test.T)\n",
        "        \n",
        "def profiling_fit(clf):\n",
        "  clf.fit(X_train, y_train, 'balanced')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wSLZOJo3_2P",
        "colab_type": "code",
        "outputId": "9d08da66-9c4c-48fe-a58d-688f6bf6f734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "print(\"PDF vs KDE vs Gaussian KDE\")\n",
        "# gmx_clf = GaussianMixtureModel()\n",
        "# %timeit -n 1 profiling_fit(gmx_clf) \n",
        "\n",
        "pdf_clf = PDFModel()\n",
        "%timeit -n 10 profiling_fit(pdf_clf)\n",
        "\n",
        "GKde_clf = GaussianKdeModel()\n",
        "%timeit -n 10 profiling_fit(GKde_clf)\n",
        "\n",
        "kde_clf = KDEModel()\n",
        "%timeit -n 10 profiling_fit(kde_clf)\n",
        "print()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PDF vs KDE vs Gaussian KDE\n",
            "10 loops, best of 3: 822 µs per loop\n",
            "10 loops, best of 3: 581 µs per loop\n",
            "10 loops, best of 3: 399 µs per loop\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEcquMhTzqlC",
        "colab_type": "code",
        "outputId": "e216ea62-1273-462c-ff3a-35fc2d064ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "print(\"LinearSVM vs Linear Kernel-SVM\")\n",
        "linearsvm_clf = LinearSvmModell2()\n",
        "%timeit -n 10 profiling_fit(linearsvm_clf)\n",
        "svm_clf = SvmModel()\n",
        "%timeit -n 10 profiling_fit(svm_clf)\n",
        "print()\n",
        "\n",
        "print(\"PCA vs Linear Kernel-PCA\")\n",
        "pca_clf = PCAModel()\n",
        "%timeit -n 10 profiling_fit(pca_clf)\n",
        "kpca_clf = KernelPCAModel()\n",
        "%timeit -n 10 profiling_fit(kpca_clf)\n",
        "print()\n",
        "\n",
        "print(\"Kmeans vs Kernel-KMeans\")\n",
        "kmeans_clf = KmeansModel()\n",
        "%timeit -n 10 profiling_fit(kmeans_clf) \n",
        "KKmeans_clf = KernelKmeansModel()\n",
        "%timeit -n 10 profiling_fit(KKmeans_clf)\n",
        "print()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearSVM vs Linear Kernel-SVM\n",
            "10 loops, best of 3: 4.52 ms per loop\n",
            "10 loops, best of 3: 11.9 ms per loop\n",
            "\n",
            "PCA vs Linear Kernel-PCA\n",
            "10 loops, best of 3: 1.39 ms per loop\n",
            "10 loops, best of 3: 42.7 ms per loop\n",
            "\n",
            "Kmeans vs Kernel-KMeans\n",
            "10 loops, best of 3: 25.6 ms per loop\n",
            "10 loops, best of 3: 12.2 s per loop\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7d9Kcju-SKJ",
        "colab_type": "code",
        "outputId": "21cd21eb-5cdf-459a-b3ba-4fb6394f1e33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "def profiling_pred_trans(clf):\n",
        "  clf.predict_or_transform(X_test) \n",
        "\n",
        "print(\"KDE vs Gaussian KDE\")\n",
        "# %timeit -n 10 profiling_pred_trans(pdf_clf)\n",
        "%timeit -n 10 profiling_pred_trans(kde_clf)\n",
        "%timeit -n 10 profiling_pred_trans(GKde_clf) \n",
        "print()\n",
        "  \n",
        "print(\"LinearSVM vs Linear Kernel-SVM\")\n",
        "%timeit -n 10 profiling_pred_trans(linearsvm_clf)\n",
        "%timeit -n 10 profiling_pred_trans(svm_clf)\n",
        "print()\n",
        "\n",
        "print(\"PCA vs Linear Kernel-PCA\")\n",
        "%timeit -n 10 profiling_pred_trans(pca_clf)\n",
        "%timeit -n 10 profiling_pred_trans(kpca_clf)\n",
        "print()\n",
        "\n",
        "print(\"Kmeans vs Kernel-KMeans\")\n",
        "%timeit -n 10 profiling_pred_trans(kmeans_clf) \n",
        "%timeit -n 10 profiling_pred_trans(KKmeans_clf)\n",
        "print()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KDE vs Gaussian KDE\n",
            "10 loops, best of 3: 3.98 ms per loop\n",
            "10 loops, best of 3: 3.9 ms per loop\n",
            "\n",
            "LinearSVM vs Linear Kernel-SVM\n",
            "10 loops, best of 3: 56.2 µs per loop\n",
            "10 loops, best of 3: 321 µs per loop\n",
            "\n",
            "PCA vs Linear Kernel-PCA\n",
            "10 loops, best of 3: 59.6 µs per loop\n",
            "10 loops, best of 3: 1.93 ms per loop\n",
            "\n",
            "Kmeans vs Kernel-KMeans\n",
            "10 loops, best of 3: 366 µs per loop\n",
            "10 loops, best of 3: 2.78 s per loop\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28-DKGpz6TxI",
        "colab_type": "text"
      },
      "source": [
        "[The](https://www.quora.com/Whats-the-difference-between-LibSVM-and-LibLinear) QP solver used in libSVM is targeted to work for both linear and non-linear kernel. The training time complexity is somewhere around O(n2) to O(n3). The solver in libLinear is targeted to primarily work with linear kernel and on top of that it offers several variations (L1/L2 regularization, L1/L2 loss etc.). The training time complexity is somewhere around O(n)."
      ]
    }
  ]
}